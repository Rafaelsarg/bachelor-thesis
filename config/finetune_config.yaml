# =============================
# üîß USER-EDITABLE PARAMETERS
# =============================

project_name: "Thesis - Safety Classification" # WanDB project name

task: "cluster"                    # Choose "safety" or "cluster"
model_id: "mistral"                # Choose from: "llama3", "phi", "mistral"
model_type: "classification"      # "classification" or "causal"


# Training hyperparameters (can be tuned)
sft_config:
  batch_size: 6             
  epochs: 3       
  lr: 2e-5                  
  evaluation_strategy: "epoch"
  gradient_accumulation_steps: 2  
  max_grad_norm: 0.3        
  lr_scheduler_type: "cosine"
  warmup_ratio: 0.05
  optim: "paged_adamw_32bit"  
  logging_steps: 10
  max_seq_length: 512
  weight_decay: 0.005
  loss_function: "custom"   # Choices: "standard", "custom" (If model type is causal, then loss_function is not applied")

# LoRA adapter setup
lora_config:
  r: 8
  alpha: 16
  target_modules: "all-linear" # Can be specific layer ["q_proj", "k_proj", "v_proj", "o_proj"]
  dropout: 0.05

# Hugging Face Token (insert your own if needed)
hf_token: "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"

# =============================
# ‚öôÔ∏è  INTERNAL CONFIG (NO CHANGE NEEDED)
# =============================

run_name: "${model_id}-${task}-${model_type}-lr${sft_config.lr}-bs${sft_config.batch_size}-${now:%Y%m%d_%H%M%S}"
group: "${task}"
tags: ["${model_id}", "${task}", "qlora", "lora"]

model_map:
  mistral: "mistralai/Mistral-7B-Instruct-v0.2"
  llama3: "meta-llama/Meta-Llama-3-8B-Instruct"
  phi: "microsoft/Phi-3-mini-4k-instruct"

dataset_config:
  dataset_map:
    safety: "data/processed/safety-dataset-90-5-5.hf"
    cluster: "data/processed/cluster-dataset-70-25-5.hf"
  dataset_path: "${dataset_config.dataset_map[${task}]}"
  num_labels_map:
    safety: 2
    cluster: 12
  num_labels: ${dataset_config.num_labels_map[${task}]}
  label_names_map:
    safety: ["Unsafe", "Safe"]
    cluster:
      - "DIET_PLAN_ISSUES"
      - "SOCIAL"
      - "SITUATIONAL"
      - "MOTIVATION"
      - "EMOTIONS"
      - "CRAVING_HABIT"
      - "MENTAL_HEALTH"
      - "ENERGY_EFFORT_CONVENIENCE"
      - "PORTION_CONTROL"
      - "KNOWLEDGE"
      - "HEALTH_CONDITION"
      - "NOT_APPLICABLE"
  label_map:
    safety:
      label2id:
        Unsafe: 0
        Safe: 1
    cluster:
      label2id:
        DIET_PLAN_ISSUES: 0
        SOCIAL: 1
        SITUATIONAL: 2
        MOTIVATION: 3
        EMOTIONS: 4
        CRAVING_HABIT: 5
        MENTAL_HEALTH: 6
        ENERGY_EFFORT_CONVENIENCE: 7
        PORTION_CONTROL: 8
        KNOWLEDGE: 9
        HEALTH_CONDITION: 10
        NOT_APPLICABLE: 11
  label2id: ${dataset_config.label_map[${task}].label2id}
  label_names: ${dataset_config.label_names_map[${task}]}

output_dir: "results/finetuning/${model_id}/${task}/${run_name}"
